---
layout: post
title: GAN
date: Fri Mar 18 00:18:35 CDT 2022
description: GAN link and papers to be read

---

## GAN reading 1: 

https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/


### part 1: training a stable GAN

Training procedure:

1. use the real image to train the discriminator
2. generate the fake image and use the fake image to train the discriminator
   - first, generate latent points (random vector/tensor)
   - second, give latent points to the generator to generate the fake image
   - third, use the fake image to train the discriminator
3. generate latent points and labels
4. use latent points and labels to train the GAN model and get the loss
   - in the GAN model training process, discriminator training is disabled; so only the generator is trained
   - the output from the GAN model (Generator + Discriminator(training disabled)) is the GAN loss
5. GAN model performance is evaluated and saved
   - generate latent points and give them to the generator to generate the fake image
   - the fake image is saved for evaluation and GAN model weights are saved

A stable GAN will have a discriminator loss around 0.5, typically between 0.5 and maybe as high as 0.7 or 0.8. The generator loss is typically higher and may hover around 1.0, 1.5, 2.0, or even higher.

The accuracy of the discriminator on both real and generated (fake) images will not be 50%, but should typically hover around 70% to 80%.

The quality generated can and does vary across the run, even after the training process becomes stable.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% responsive_image path: assets/img/The-basic-structure-of-the-generative-adversarial-network-GAN-model.jpg class: "img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
The basic structure of the generative adversarial network GAN model
</div>

##### * what is latent space?
Reading: https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d


### part 2: identifying a mode collapse in GAN
With a GAN generator model, a mode failure means that the vast number of points in the input latent space (e.g. hypersphere of 100 dimensions in many cases) result in one or a small subset of generated images.

(* "mode" regers to an output distribution.)

signs of mode collapse:
1. generated images showing low diversity
2. loss plot for generator (and probably the discriminator) showing oscillations over time

ways to solve:
1. restrict the size of the latent dimensions directly (forcing the model to only generate a small subset of plausible outputs)
2. check if the data size is too small



======

link:

https://machinelearningmastery.com/practical guide-to-gan-failure-modes/
 
https://www.coursera.org/specializations/generative-adversarial-networks-gans

PDF:

https://arxiv.org/pdf/1807.03401.pdf

https://pubs.rsna.org/doi/full/10.1148/ryai.2020190181

